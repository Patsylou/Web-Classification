 Previously in Digital Culture: "Coming of Age in Cyberspace," by David S. Bennahum (October 28, 1998) Extra Life. "Portable Musings," by Sven Birkerts (September 10, 1998) "The Invisible World Order," by Andrew Piper (July 29, 1998) "The Right Mix," by Ralph Lombreglia (June 4, 1998) "A Function Specific to Joy," by Harvey Blume (April 29, 1998) More on Technology and Digital Culture in Atlantic Unbound and The Atlantic Monthly. Technology & Digital Culture conference of Post & Riposte . Can robotics shed light on the human mind? On evolution? Daniel Dennett -- whose work unites neuroscience, computer science, and evolutionary biology -- has some provocative answers. Is he on to something, or just chasing the zeitgeist? by Harvey Blume December 9, 1998 B ack when I was a student of philosophy, in the late sixties, it was customary to divide the discipline into two schools: "analytic" and "continental." Continental philosophers typically built up large edifices of meaning. Analytic philosophers broke large systems down, scrutinizing every brick. Continental philosophers at times overreached, acting as though thought alone were capable of storming the gates of heaven and hell. Analytic philosophers were at times intellectually stingy. If continental philosophy could sound like poetry or music, analytic philosophy seemed anxious to sound like science. Georg Wilhelm Friedrich Hegel, who saw every aspect of history, politics, religion, and art as a moment in the unfolding of the World Spirit, might be nominated to be the standard bearer for continental philosophy. Ludwig Wittgenstein might be picked, on behalf of analytic philosophy, to deflate Hegel's overflowing theses and antitheses. Wittgenstein, after all, is well known for writing, in Tractatus Logico-Philosophicus (1921), "What we cannot speak about we must pass over in silence." A Conversation Harvey Blume interviews the philosopher who never met a robot he didn't like. Center for Cognitive Studies at Tufts University, points not only to an array of contemporary issues but also to the continental-analytic fault line that runs through philosophy itself. When I started reading Dennett recently, I thought at first that I was dealing with an analytic philosopher who used artificial intelligence and computer science to pare philosophical problems down to manageable size. That's true as far as it goes -- it's tempting to say that Dennett has never met a robot he didn't like, and that what he likes most about them is that they are philosophical experiments. Instead of arguing interminably about how a mind works, Dennett believes it makes sense to build one, however rudimentary, and set it loose to see what it can do. If you're staging a Turing Test, in order to see if a computer can fool humans into thinking it is truly intelligent, Dennett would be exactly the philosopher to sit on the board of judges -- as he has several times. If you're designing a state-of-the-art robot in order to see how it negotiates the real world (or some subset thereof), Dennett would be the man for your team -- and not surprisingly he does have ties to the artificial intelligence (AI) community, and is invited to go where other philosophers are not encouraged or have no wish to go. He works closely, for example, with Rod Brooks, the head of MIT's AI Lab , on the design of Cog the "cognitive robot." Cog the "cognitive robot." Alan Turing , the question of machine intelligence has become a central theme of our time -- and here, as elsewhere, Dennett brings analytic rigor to bear. To the question of whether machines can attain high-order intelligence, Dennett makes this provocative answer: "The best reason for believing that robots might some day become conscious is that we human beings are conscious, and we are a sort of robot ourselves." Daniel Dennett , in an interview with Harvey Blume. lan vital, or, to use Dennett's term, a "sky-hook"), how can you be sure that life, cooked up over eons in the laboratory of nature, is different -- fundamentally, rather than by degree of refinement -- from the models produced in an AI lab? The Society of Mind ), Freud was ahead of his time in showing how the ego stole its precious self-awareness from the activities of innumerable processes that are anything but self-aware -- in other words, from the unconscious. Freud's unconscious becomes a placeholder for neural networking, massively distributed parallel processing, or some other trick of wiring that will one day allow Cog or one of its kin to be launched mindfully into the world. D ennett is a skillful writer who has probed mind-body-machine connections in his books Brainstorms: Philosophical Essays on Mind and Psychology (1978), Consciousness Explained (1991), and Brainchildren: Essays on Designing Minds (1998). When I met with him recently in his office at Tufts, he was quick to acknowledge how difficult it is to talk about the mind these days without using metaphors drawn from computer science. In his view, this is just fine. "Taking on new concepts," he said, "new ways of thinking about things, so that you suddenly open up new model spaces to explore -- that's great, but you are also tying your hands when you do that." He continued, "Now, it's very important that you tie your hands. Working under constraint is a necessary condition for really important inventions. All the great art of the Renaissance was done under the constraint that it had to be in the service of Christian iconography. Can you make great art under those circumstances? You sure can. Would they have made greater art if they had been free bohemians instead of coddled slaves of bishops and dukes? No, I don't think so." Darwin's Dangerous Idea: Evolution and the Meanings of Life (1995), Dennett points out that Charles Babbage (the mathematician and early computer pioneer) and Charles Darwin attended the same London parties, probably chewed the same mutton, and quite possibly discussed some of the notions that later became so hugely influential in evolutionary theory and computer science. The meeting of Darwin and Babbage brought a central idea of Darwin's Dangerous Idea alive for me -- namely, that evolution and computers are driven by similar processes that are familiar, at least in part, to any software engineer. You write small pieces of dumb code that work with other simple pieces of code in order to produce systems of greater complexity, which in turn interact with other complex systems in order to give higher degrees of functionality, and so on, until you wind up with a program that is smart -- or, at least, smart enough to do something that needs doing. Finally, you get operating systems, you get an Internet -- or, depending on your raw materials and the time allotted, you get DNA, mammals, and self-awareness. Daniel Dennett , in an interview with Harvey Blume. Darwin's Dangerous Idea argues that evolution is not a feat of pure thought or of magic or of brilliant planning but simply of engineering over time -- except that it's a case of engineering minus any particular engineer, design minus a designer. In a sense, you have a synthesis as broad as any Hegel attempted, but instead of the World Spirit you have dumb processes of evolution that all on their own suffice to bring about animation, self-replication, intelligence, and the rest. Does evolution obey the dictates of some presiding genius? Does it require a bit of divine guidance? No. Is it nevertheless sensible to think of it as possessing an intelligence that can be usefully compared to that of thermostats and minds? Yes. Next page ... A Conversation With Daniel Dennett Technology & Digital Culture conference of Post & Riposte . More on Technology and Digital Culture in Atlantic Unbound and The Atlantic Monthly. Harvey Blume , a writer living in Cambridge, Massachusetts, is a frequent contributor to Atlantic Unbound. Copyright 1998 by The Atlantic Monthly Company. All rights reserved. 
